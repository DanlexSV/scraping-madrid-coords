{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Dg-9dwqYn5hA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d6a91e-aba6-45f9-f50e-138af5cfeb76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total filas: 179\n",
            "CSV generado correctamente\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import re\n",
        "import time\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "BASE_URL = \"https://www.coordenadas.com.es\"\n",
        "START_PATH = \"/espana/pueblos-de-madrid/28/1\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (compatible; simple-scraper/1.0)\"\n",
        "}\n",
        "\n",
        "def get_soup(url: str) -> BeautifulSoup:\n",
        "    r = requests.get(url, headers=HEADERS, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    return BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "def extract_total_pages(soup: BeautifulSoup) -> int:\n",
        "    pag = soup.select_one(\"ul.pagination\")\n",
        "    if not pag:\n",
        "        return 1\n",
        "\n",
        "    max_page = 1\n",
        "    for a in pag.select(\"a[href]\"):\n",
        "        m = re.search(r\"/espana/pueblos-de-madrid/28/(\\d+)\", a[\"href\"])\n",
        "        if m:\n",
        "            max_page = max(max_page, int(m.group(1)))\n",
        "    return max_page\n",
        "\n",
        "def parse_table_rows(soup: BeautifulSoup):\n",
        "    table = soup.select_one(\"table.table\")\n",
        "    if not table:\n",
        "        return []\n",
        "\n",
        "    results = []\n",
        "    for tr in table.select(\"tbody tr\"):\n",
        "        tds = tr.select(\"td\")\n",
        "        if len(tds) < 3:\n",
        "            continue\n",
        "\n",
        "        a = tds[0].select_one(\"a\")\n",
        "        if not a:\n",
        "            continue\n",
        "\n",
        "        city = re.sub(r\"^Coordenadas\\s+\", \"\", a.get_text(strip=True))\n",
        "\n",
        "        coords = tds[2].get_text(strip=True)\n",
        "        if \",\" not in coords:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            lat, lon = map(float, coords.split(\",\", 1))\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        results.append({\"city\": city, \"lat\": lat, \"lon\": lon})\n",
        "\n",
        "    return results\n",
        "\n",
        "def scrape_all():\n",
        "    soup = get_soup(urljoin(BASE_URL, START_PATH))\n",
        "    total_pages = extract_total_pages(soup)\n",
        "\n",
        "    all_rows = []\n",
        "    for page in range(1, total_pages + 1):\n",
        "        url = urljoin(BASE_URL, f\"/espana/pueblos-de-madrid/28/{page}\")\n",
        "        rows = parse_table_rows(get_soup(url))\n",
        "        all_rows.extend(rows)\n",
        "        time.sleep(0.8)\n",
        "\n",
        "    return all_rows\n",
        "\n",
        "def save_csv(rows, filename=\"pueblos_madrid_coords.csv\"):\n",
        "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=[\"city\", \"lat\", \"lon\"])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(rows)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rows = scrape_all()\n",
        "    print(f\"Total filas: {len(rows)}\")\n",
        "    save_csv(rows)\n",
        "    print(\"CSV generado correctamente\")\n"
      ]
    }
  ]
}